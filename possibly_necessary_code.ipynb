{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "possibly_necessary_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmZ32UyhD7MIrOQxFFSafb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/El-Nico/tensorflow-notes/blob/main/possibly_necessary_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###data preprocessing"
      ],
      "metadata": {
        "id": "MkYEgS0DYTGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####dealing with zip files"
      ],
      "metadata": {
        "id": "89nCWguyY8uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download zip file of pizza_steak images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip \n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "\n",
        "!ls pizza_steak\n",
        "\n",
        "!ls pizza_steak/train/\n",
        "\n",
        "!ls pizza_steak/train/steak/"
      ],
      "metadata": {
        "id": "ZICxTBx6ZKJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of file structure\n",
        "\n",
        "pizza_steak <- top level folder\n",
        "└───train <- training images\n",
        "│   └───pizza\n",
        "│   │   │   1008104.jpg\n",
        "│   │   │   1638227.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   1000205.jpg\n",
        "│       │   1647351.jpg\n",
        "│       │   ...\n",
        "│   \n",
        "└───test <- testing images\n",
        "│   └───pizza\n",
        "│   │   │   1001116.jpg\n",
        "│   │   │   1507019.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   100274.jpg\n",
        "│       │   1653815.jpg\n",
        "│       │   ..."
      ],
      "metadata": {
        "id": "INLsuypzZbIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10_food_classes directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "  ############################################################################\n",
        "  # Get the class names for our multi-class dataset\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)\n",
        "\n",
        "#######################################################\n",
        "# View a random image from the training dataset\n",
        "import random\n",
        "img = view_random_image(target_dir=train_dir,\n",
        "                        target_class=random.choice(class_names)) # get a random class name"
      ],
      "metadata": {
        "id": "JjvWwB-nfXhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###learning rate"
      ],
      "metadata": {
        "id": "jVVgVNKTpNbx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFt0CujIpHmd"
      },
      "outputs": [],
      "source": [
        "#creating a learning rate scheduler callback\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))# traverse a set of learning rates strating from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "#fit the model for 100 epochs\n",
        "# history=fashion.fit(train_images,\n",
        "#                     train_labels, epochs=50, \n",
        "#                     validation_data=(test_images, test_labels),\n",
        "#                     callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout the history\n",
        "#pd.DataFrame(history.history).plot(figsize=(10,7), xlabel=\"epochs\");"
      ],
      "metadata": {
        "id": "AqjR61e9piO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "# lrs = 1e-4 * (10 ** (np.arange(100)/20))\n",
        "# plt.figure(figsize=(10, 7))\n",
        "# plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "# plt.xlabel(\"Learning Rate\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "bwu4a623pyfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![how to select the best learning rate](https://raw.githubusercontent.com/El-Nico/tensorflow-notes/main/tensorflow_notes_images/learning_rate.png)"
      ],
      "metadata": {
        "id": "31ctrT8Gw1Q8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###creating a confusion matrix"
      ],
      "metadata": {
        "id": "i8yD7H-Sx5PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred=fashion_non_normal.predict(test_images)\n",
        "\n",
        "# y_pred.shape\n"
      ],
      "metadata": {
        "id": "MoDJ_4l2IW25",
        "outputId": "354405e3-6d3f-4815-a332-2587d5fdc739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the prediction from probs to labels\n",
        "# y_pred=y_pred.argmax(axis=-1)\n",
        "# y_pred.shape"
      ],
      "metadata": {
        "id": "GudYjyf3KB_t",
        "outputId": "512a5131-f09b-4c75-b33e-5d9184bf52f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "             size=text_size)"
      ],
      "metadata": {
        "id": "Q9SzFA4tHBuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###viewing random images"
      ],
      "metadata": {
        "id": "CX5rJ6ofRFaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "  \"\"\"\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels \n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img\n",
        "\n",
        "#####################################################################################\n",
        "  # Load in and preprocess our custom image\n",
        "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
        "steak"
      ],
      "metadata": {
        "id": "bjmtj4GJRLvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hYIB4vq8erHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###this is for test results to visualize prediction accuracy\n",
        "import random\n",
        "\n",
        "# Create a function for plotting a random image along with its prediction\n",
        "def plot_random_image(model, images, true_labels, classes):\n",
        "  \"\"\"Picks a random image, plots it and labels it with a predicted and truth label.\n",
        "\n",
        "  Args:\n",
        "    model: a trained model (trained on data similar to what's in images).\n",
        "    images: a set of random images (in tensor form).\n",
        "    true_labels: array of ground truth labels for images.\n",
        "    classes: array of class names for images.\n",
        "  \n",
        "  Returns:\n",
        "    A plot of a random image from `images` with a predicted class label from `model`\n",
        "    as well as the truth class label from `true_labels`.\n",
        "  \"\"\" \n",
        "  # Setup random integer\n",
        "  i = random.randint(0, len(images))\n",
        "  \n",
        "  # Create predictions and targets\n",
        "  target_image = images[i]\n",
        "  pred_probs = model.predict(target_image.reshape(1, 28, 28)) # have to reshape to get into right size for model\n",
        "  pred_label = classes[pred_probs.argmax()]\n",
        "  true_label = classes[true_labels[i]]\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(target_image, cmap=plt.cm.binary)\n",
        "\n",
        "  # Change the color of the titles depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Add xlabel information (prediction/true label)\n",
        "  plt.xlabel(\"Pred: {} {:2.0f}% (True: {})\".format(pred_label,\n",
        "                                                   100*tf.reduce_max(pred_probs),\n",
        "                                                   true_label),\n",
        "             color=color) # set the color to green or red"
      ],
      "metadata": {
        "id": "iq7ZZz6lNRVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is to view a random image from array of images\n",
        "# Show original image and augmented image\n",
        "random_number = random.randint(0, 32) # we're making batches of size 32, so we'll get a random instance\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(f\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(f\"Augmented image\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "mBdYsr-6dsor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###convolution"
      ],
      "metadata": {
        "id": "p4lVIlJbaEfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#architecture of a basic convolution neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup the train and test directories\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32, # number of images to process at a time \n",
        "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
        "                                               class_mode=\"binary\", # type of problem we're working on\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10, \n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\", \n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "7-zA3_V_aMjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###evaluating and visualizing models"
      ],
      "metadata": {
        "id": "6-mueSIbcvUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####plotting the loss curves"
      ],
      "metadata": {
        "id": "fZgY4qa7c1OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "jdtjBJhuc6hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust function to work with multi-class\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "QlESdejcfHkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###saving and loading models"
      ],
      "metadata": {
        "id": "LWHJmDbsgTdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a model\n",
        "model_11.save(\"saved_trained_model\")\n",
        "\n",
        "###############################\n",
        "# Load in a model and evaluate it\n",
        "loaded_model_11 = tf.keras.models.load_model(\"saved_trained_model\")\n",
        "loaded_model_11.evaluate(test_data)\n",
        "\n",
        "###################################\n",
        "# Compare our unsaved model's results (same as above)\n",
        "model_11.evaluate(test_data)"
      ],
      "metadata": {
        "id": "-i-G9DrigWg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###find out how many images in a file"
      ],
      "metadata": {
        "id": "i4Rc-pngXQhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "ZKmCv_vJXUaQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}